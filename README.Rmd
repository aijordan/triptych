---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# triptych : Diagnostic Graphics to Evaluate Forecast Performance

<!-- badges: start -->
[![CRAN status](https://www.r-pkg.org/badges/version/triptych)](https://CRAN.R-project.org/package=triptych)
[![R-CMD-check](https://github.com/aijordan/triptych/actions/workflows/R-CMD-check.yaml/badge.svg)](https://github.com/aijordan/triptych/actions/workflows/R-CMD-check.yaml)
<!-- badges: end -->

Overall predictive performance is measured by a mean score (or loss), which decomposes into miscalibration, discrimination, and uncertainty components.
The main focus is visualization of these distinct and complementary aspects in joint displays. See Dimitriadis, Gneiting, Jordan, Vogel (2023) [arXiv:2301.10803](https://arxiv.org/abs/2301.10803).

## Installation

Install the latest release of triptych from CRAN with:

``` r
install.packages("triptych")
```


Install the development version of triptych with:

``` r
# install.packages("devtools")
devtools::install_github("aijordan/triptych")
```

## Example

```{r example_triptych, fig.width = 10, fig.height = 4}
library(triptych)
data(ex_binary, package = "triptych")
set.seed(20230921)

tr <- triptych(ex_binary)
tr

# 1. Choose 4 predictions
# 2. Add consistency bands (for reliability curves)
# 3. Create patchwork object
# 4. Adjust the title of the legend
dplyr::slice(tr, 1, 3, 6, 9) |>
  add_consistency(level = 0.9, n_boot = 100) |>
  autoplot() &
  ggplot2::guides(colour = ggplot2::guide_legend("Forecast"))
```

```{r example_MCBDSC, out.width = "50%", fig.align="center", fig.height = 6, fig.width = 6}
# From existing triptych object
estimates(tr$mcbdsc)
autoplot(tr$mcbdsc)

# Or standalone:
# mcbdsc(ex_binary) |> estimates()
# mcbdsc(ex_binary) |> autoplot()
```
